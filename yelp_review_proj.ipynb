{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC_zKf5A7poz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, LSTM, Embedding, Flatten, GRU\n",
        "from keras.utils import to_categorical\n",
        "%matplotlib inline\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYQp3bWe71C6",
        "outputId": "a6cd9e01-73d7-48da-dcfa-9562af057eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "vpNMEon68ZHj",
        "outputId": "26be532f-2765-44e5-ea39-54ab0145f11a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "/content/drive/MyDrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "%cd ..\n",
        "%cd /content/drive/MyDrive\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGLvuonCLGTr",
        "outputId": "43b025f2-676a-4e20-9581-c3bad5fc9d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUmcr8QV9A8O"
      },
      "outputs": [],
      "source": [
        "# import the data (chunksize returns jsonReader for iteration)\n",
        "businesses = pd.read_json(\"yelp_academic_dataset_business.json\", lines=True, orient='columns', chunksize=100000)\n",
        "reviews = pd.read_json(\"yelp_academic_dataset_review.json\", lines=True, orient='columns', chunksize=100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNUG3XoP9FlC"
      },
      "outputs": [],
      "source": [
        "# read the data\n",
        "for business in businesses:\n",
        "    business_chunk = business\n",
        "    break\n",
        "\n",
        "for review in reviews:\n",
        "    review_chunk = review\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er4MLGJg9rGa"
      },
      "outputs": [],
      "source": [
        "display(business_chunk.head(2))\n",
        "display(review_chunk.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diqoxsmi9vfe",
        "outputId": "2226a4a8-619b-444e-91ac-4e90b7a59052"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72125, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "a = business_chunk[business['categories'].str.contains('Restaurant') == True]\n",
        "rev = review_chunk[review_chunk.business_id.isin(a['business_id']) == True]\n",
        "rev.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9aL2Pkoeu9O",
        "outputId": "ebff5544-c9aa-4190-a963-d5ef853ac6f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3\n",
              "2    3\n",
              "3    5\n",
              "4    4\n",
              "5    1\n",
              "Name: stars, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "rev['stars'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulLx5I1YN0M",
        "outputId": "53fdec0d-297e-4850-e811-c482fe96cd1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 9), (35000, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "sample_size = 35000\n",
        "rev_sample = rev.sample(n=sample_size, random_state=42)\n",
        "rev_score1 = rev[rev['stars'].isin([1,5])]\n",
        "rev_score2 = rev[rev['stars'].isin([2,3,4])]\n",
        "rev_score1_sample = rev_score1.sample(n=sample_size, random_state=12)\n",
        "rev_score2_sample = rev_score2.sample(n=sample_size, random_state=22)\n",
        "rev_score1_sample.shape, rev_score2_sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iqCDa1J9wWC"
      },
      "outputs": [],
      "source": [
        "maxlen = 500\n",
        "review_cnt_limit = 15000\n",
        "\n",
        "# import GLoVE embeddings\n",
        "embedding_file = 'glove.6B.300d.txt'\n",
        "\n",
        "# read in embeddings\n",
        "def load_glove_embeddings(embedding_file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(embedding_file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_embeddings = load_glove_embeddings(embedding_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o14COn-N98oL"
      },
      "outputs": [],
      "source": [
        "glove_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdMt9d4qJpAt"
      },
      "outputs": [],
      "source": [
        "def clean_and_tokenize(string):\n",
        "    lem = WordNetLemmatizer()\n",
        "    return [lem.lemmatize(word) for word in word_tokenize(re.sub(r\"[^\\w\\s]\", \"\", string))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbAMCwuKmYY8"
      },
      "outputs": [],
      "source": [
        "rev_sample = rev_sample[['text','stars']]\n",
        "rev_score1_sample = rev_score1_sample[['text','stars']]\n",
        "rev_score2_sample = rev_score2_sample[['text','stars']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN8oJ-RvJ0is"
      },
      "outputs": [],
      "source": [
        "rev_sample[\"lemmatized_text\"] = rev_sample[\"text\"].apply(clean_and_tokenize)\n",
        "rev_score1_sample[\"lemmatized_text\"] = rev_score1_sample[\"text\"].apply(clean_and_tokenize)\n",
        "rev_score2_sample[\"lemmatized_text\"] = rev_score2_sample[\"text\"].apply(clean_and_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pL4jn8x99JX"
      },
      "outputs": [],
      "source": [
        "# this is lemmatized data for original score\n",
        "rev_lemmatized = rev_sample[['lemmatized_text', 'stars']]\n",
        "tokenizer = Tokenizer(num_words=review_cnt_limit)\n",
        "tokenizer.fit_on_texts(rev_lemmatized['lemmatized_text'])\n",
        "sequence = tokenizer.texts_to_sequences(rev_lemmatized['lemmatized_text'])\n",
        "padded_sequences = pad_sequences(sequence, maxlen=maxlen)\n",
        "\n",
        "# this is lemmatized data for model 1, extreme score model\n",
        "rev_lemmatized_extreme = rev_sample[['lemmatized_text', 'stars']]\n",
        "tokenizer_extreme = Tokenizer(num_words=review_cnt_limit)\n",
        "tokenizer_extreme.fit_on_texts(rev_lemmatized_extreme['lemmatized_text'])\n",
        "sequence_extreme = tokenizer_extreme.texts_to_sequences(rev_lemmatized_extreme['lemmatized_text'])\n",
        "padded_sequences_extreme = pad_sequences(sequence_extreme, maxlen=maxlen)\n",
        "\n",
        "# this is the lemaatized data for model 2, 1&5 start score model\n",
        "rev_lemmatized_15 = rev_score1_sample[['lemmatized_text', 'stars']]\n",
        "tokenizer_15 = Tokenizer(num_words=review_cnt_limit)\n",
        "tokenizer_15.fit_on_texts(rev_lemmatized_15['lemmatized_text'])\n",
        "sequence_15 = tokenizer_15.texts_to_sequences(rev_lemmatized_15['lemmatized_text'])\n",
        "padded_sequences_15 = pad_sequences(sequence_15, maxlen=maxlen)\n",
        "\n",
        "# this is the lemaatized data for model 3, 2&3&4 start score model\n",
        "rev_lemmatized_234 = rev_score2_sample[['lemmatized_text', 'stars']]\n",
        "tokenizer_234 = Tokenizer(num_words=review_cnt_limit)\n",
        "tokenizer_234.fit_on_texts(rev_lemmatized_234['lemmatized_text'])\n",
        "sequence_234 = tokenizer_234.texts_to_sequences(rev_lemmatized_234['lemmatized_text'])\n",
        "padded_sequences_234 = pad_sequences(sequence_234, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv_7OBNqNHVh"
      },
      "outputs": [],
      "source": [
        "rev_lemmatized_extreme['extreme_rate'] = rev_lemmatized_extreme['stars'].map(lambda x: 1 if x in [1, 5] else 0)\n",
        "rev_lemmatized_extreme = rev_lemmatized_extreme[['lemmatized_text','extreme_rate']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maID2TmrOG1P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "213d7af1-e116-4baa-fead-f5601a42b81b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         lemmatized_text  extreme_rate\n",
              "22934  [Hey, kid, did, you, know, that, Vietnam, wa, ...             0\n",
              "31476  [If, you, think, you, are, walking, into, a, t...             1\n",
              "33033  [This, place, is, pretty, good, A, little, on,...             0\n",
              "72060  [Enjoy, a, taste, of, classic, Nashville, but,...             0\n",
              "41227  [Not, closed, They, have, temporary, hour, rig...             0\n",
              "97648  [An, exquisite, and, delicious, Parisian, esca...             1\n",
              "37395  [Solid, 35, star, I, wa, pleasantly, surprised...             0\n",
              "65991  [First, impression, bad, restaurant, hostess, ...             1\n",
              "74883  [Sweet, and, Sassy, seems, to, be, a, regular,...             1\n",
              "12681  [Love, this, place, their, green, passion, smo...             1\n",
              "52334  [No, draft, beer, Bottles, only, Great, happy,...             0\n",
              "33195  [One, of, my, favorite, coffee, stop, The, lad...             1\n",
              "72061  [Chicken, finger, were, good, The, sauce, wa, ...             0\n",
              "8034   [Love, the, atmosphere, and, surprise, salad, ...             1\n",
              "31705  [I, came, to, Indian, rock, beach, to, the, Ji...             0\n",
              "62508  [Drinks, and, staff, awesome, Great, place, to...             0\n",
              "11696  [A, small, storefront, kitchen, serving, IndoP...             0\n",
              "89408  [Went, to, Red, Mesa, the, other, night, with,...             0\n",
              "90181  [Third, time, here, and, I, got, the, manager,...             1\n",
              "44108  [A, very, casual, atmosphere, with, good, dine...             0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45e5b173-b62a-4d77-8fed-8bb9b38e57f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>extreme_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22934</th>\n",
              "      <td>[Hey, kid, did, you, know, that, Vietnam, wa, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31476</th>\n",
              "      <td>[If, you, think, you, are, walking, into, a, t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33033</th>\n",
              "      <td>[This, place, is, pretty, good, A, little, on,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72060</th>\n",
              "      <td>[Enjoy, a, taste, of, classic, Nashville, but,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41227</th>\n",
              "      <td>[Not, closed, They, have, temporary, hour, rig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97648</th>\n",
              "      <td>[An, exquisite, and, delicious, Parisian, esca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37395</th>\n",
              "      <td>[Solid, 35, star, I, wa, pleasantly, surprised...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65991</th>\n",
              "      <td>[First, impression, bad, restaurant, hostess, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74883</th>\n",
              "      <td>[Sweet, and, Sassy, seems, to, be, a, regular,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12681</th>\n",
              "      <td>[Love, this, place, their, green, passion, smo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52334</th>\n",
              "      <td>[No, draft, beer, Bottles, only, Great, happy,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33195</th>\n",
              "      <td>[One, of, my, favorite, coffee, stop, The, lad...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72061</th>\n",
              "      <td>[Chicken, finger, were, good, The, sauce, wa, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8034</th>\n",
              "      <td>[Love, the, atmosphere, and, surprise, salad, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31705</th>\n",
              "      <td>[I, came, to, Indian, rock, beach, to, the, Ji...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62508</th>\n",
              "      <td>[Drinks, and, staff, awesome, Great, place, to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11696</th>\n",
              "      <td>[A, small, storefront, kitchen, serving, IndoP...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89408</th>\n",
              "      <td>[Went, to, Red, Mesa, the, other, night, with,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90181</th>\n",
              "      <td>[Third, time, here, and, I, got, the, manager,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44108</th>\n",
              "      <td>[A, very, casual, atmosphere, with, good, dine...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45e5b173-b62a-4d77-8fed-8bb9b38e57f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45e5b173-b62a-4d77-8fed-8bb9b38e57f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45e5b173-b62a-4d77-8fed-8bb9b38e57f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a0bdda4a-c8ab-4f0c-a028-494b507fa455\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0bdda4a-c8ab-4f0c-a028-494b507fa455')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a0bdda4a-c8ab-4f0c-a028-494b507fa455 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "rev_lemmatized_extreme.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erzpiokSW1PQ",
        "outputId": "0d4169c7-10ee-44d9-f0b6-c1cb43456534"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "rev_lemmatized_extreme.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M94VqmPE9_oo"
      },
      "outputs": [],
      "source": [
        "# modification made to encoding\n",
        "# we want to split score into two group 1&5, 2,3 and 4 by adding a new feature\n",
        "# we noticed 1&5 score have higher accuracy so we want seperate them out and train a model solely on 2,3,4\n",
        "label_encoder = LabelEncoder()\n",
        "# this is the original y for training on scores\n",
        "y = label_encoder.fit_transform(rev_lemmatized['stars'])\n",
        "\n",
        "# the extreme score is to differentiate between 1&5 star and 2,3,4 stars\n",
        "y_extreme = label_encoder.fit_transform(rev_lemmatized_extreme['extreme_rate'])\n",
        "\n",
        "# the score is to predict the actual rating\n",
        "y_score_15 = label_encoder.fit_transform(rev_lemmatized_15['stars'])\n",
        "y_score_234 = label_encoder.fit_transform(rev_lemmatized_234['stars'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UvVQ6fkKjjO"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(y)\n",
        "y_extreme = to_categorical(y_extreme)\n",
        "y_score_15 = to_categorical(y_score_15)\n",
        "y_score_234 = to_categorical(y_score_234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9-G8j18-Bb7"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size = 0.3, random_state=42)\n",
        "X_train_extreme, X_test_extreme, y_train_extreme, y_test_extreme = train_test_split(padded_sequences_extreme, y_extreme, test_size = 0.3, random_state=52)\n",
        "X_train_15, X_test_15, y_train_15, y_test_15 = train_test_split(padded_sequences_15, y_score_15, test_size = 0.4, random_state=100)\n",
        "X_train_234, X_test_234, y_train_234, y_test_234 = train_test_split(padded_sequences_234, y_score_234, test_size = 0.4, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXBeXy50-LC2"
      },
      "outputs": [],
      "source": [
        "# Finding the assigned vector for each word in the embedding and assign it back to words\n",
        "# Original score\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(review_cnt_limit,len(word_index))+1\n",
        "embedding_dimension = 300\n",
        "embedding_matrix = np.zeros((num_words, embedding_dimension))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i > review_cnt_limit:\n",
        "        continue\n",
        "    embedding_vector = glove_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Extreme Score\n",
        "word_index_extreme = tokenizer_extreme.word_index\n",
        "num_words_extreme = min(review_cnt_limit,len(word_index_extreme))+1\n",
        "embedding_matrix_extreme = np.zeros((num_words_extreme, embedding_dimension))\n",
        "for word, i in tokenizer_extreme.word_index.items():\n",
        "    if i > review_cnt_limit:\n",
        "        continue\n",
        "    embedding_vector_extreme = glove_embeddings.get(word)\n",
        "    if embedding_vector_extreme is not None:\n",
        "        embedding_matrix_extreme[i] = embedding_vector_extreme\n",
        "\n",
        "# 1 star & 5 star score\n",
        "word_index_15 = tokenizer_15.word_index\n",
        "num_words_15 = min(review_cnt_limit,len(word_index_15))+1\n",
        "embedding_matrix_15 = np.zeros((num_words_15, embedding_dimension))\n",
        "for word, i in tokenizer_15.word_index.items():\n",
        "    if i > review_cnt_limit:\n",
        "        continue\n",
        "    embedding_vector_15 = glove_embeddings.get(word)\n",
        "    if embedding_vector_15 is not None:\n",
        "        embedding_matrix_15[i] = embedding_vector_15\n",
        "\n",
        "# 2, 3, 4 star score\n",
        "word_index_234 = tokenizer_234.word_index\n",
        "num_words_234 = min(review_cnt_limit,len(word_index_234))+1\n",
        "embedding_matrix_234 = np.zeros((num_words_234, embedding_dimension))\n",
        "for word, i in tokenizer_234.word_index.items():\n",
        "    if i > review_cnt_limit:\n",
        "        continue\n",
        "    embedding_vector_234 = glove_embeddings.get(word)\n",
        "    if embedding_vector_234 is not None:\n",
        "        embedding_matrix_234[i] = embedding_vector_234"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hudw73Vn-S-a"
      },
      "outputs": [],
      "source": [
        "# We will fit 3 models, the first model to predict whether the rating is extreme rating or not\n",
        "# second model predict the score between 1 & 5\n",
        "# third model predict the score between 2,3,4\n",
        "# using the same setting for my neural network models, but fit different label and input variables\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, embedding_dimension, input_length=maxlen, weights=[embedding_matrix], trainable=False))\n",
        "model.add(LSTM(40))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model_extreme = Sequential()\n",
        "model_extreme.add(Embedding(num_words_extreme, embedding_dimension, input_length=maxlen, weights=[embedding_matrix_extreme], trainable=False))\n",
        "model_extreme.add(LSTM(40))\n",
        "model_extreme.add(Dense(32, activation='relu'))\n",
        "model_extreme.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model_15 = Sequential()\n",
        "model_15.add(Embedding(num_words_15, embedding_dimension, input_length=maxlen, weights=[embedding_matrix_15], trainable=False))\n",
        "model_15.add(LSTM(40))\n",
        "model_15.add(Dense(32, activation='relu'))\n",
        "model_15.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model_234 = Sequential()\n",
        "model_234.add(Embedding(num_words_234, embedding_dimension, input_length=maxlen, weights=[embedding_matrix_234], trainable=False))\n",
        "model_234.add(LSTM(40))\n",
        "model_234.add(Dense(32, activation='relu'))\n",
        "model_234.add(Dense(len(label_encoder.classes_), activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBv6P1yO-Txt"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-qENhBR-U3I"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_extreme.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_15.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_234.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_RUE0duJYDs",
        "outputId": "161ba012-9b40-4cb1-9f2f-c81e4136038c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "307/307 [==============================] - 239s 772ms/step - loss: 1.2289 - accuracy: 0.4662 - val_loss: 1.0406 - val_accuracy: 0.5365\n",
            "Epoch 2/10\n",
            "307/307 [==============================] - 234s 764ms/step - loss: 0.9808 - accuracy: 0.5695 - val_loss: 0.9787 - val_accuracy: 0.5682\n",
            "Epoch 3/10\n",
            "307/307 [==============================] - 237s 771ms/step - loss: 0.9007 - accuracy: 0.6010 - val_loss: 0.9039 - val_accuracy: 0.6055\n",
            "Epoch 4/10\n",
            "307/307 [==============================] - 235s 767ms/step - loss: 0.8548 - accuracy: 0.6254 - val_loss: 0.8911 - val_accuracy: 0.6122\n",
            "Epoch 5/10\n",
            "307/307 [==============================] - 233s 757ms/step - loss: 0.8213 - accuracy: 0.6362 - val_loss: 0.8814 - val_accuracy: 0.6088\n",
            "Epoch 6/10\n",
            "307/307 [==============================] - 236s 771ms/step - loss: 0.7845 - accuracy: 0.6538 - val_loss: 0.8816 - val_accuracy: 0.6131\n",
            "Epoch 7/10\n",
            "307/307 [==============================] - 237s 772ms/step - loss: 0.7559 - accuracy: 0.6676 - val_loss: 0.9205 - val_accuracy: 0.6080\n",
            "Epoch 8/10\n",
            "307/307 [==============================] - 233s 759ms/step - loss: 0.7240 - accuracy: 0.6835 - val_loss: 0.8920 - val_accuracy: 0.6173\n",
            "Epoch 9/10\n",
            "307/307 [==============================] - 230s 752ms/step - loss: 0.6963 - accuracy: 0.6948 - val_loss: 0.9133 - val_accuracy: 0.6071\n",
            "Epoch 10/10\n",
            "307/307 [==============================] - 232s 757ms/step - loss: 0.6607 - accuracy: 0.7141 - val_loss: 0.9330 - val_accuracy: 0.6049\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d474eaffd90>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the performance of the original NN model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Accuracy score is \", accuracy, \"Loss is \", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHPetJVEM1Rs",
        "outputId": "70938062-f57b-47b6-8526-92e3d4d34f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329/329 [==============================] - 36s 109ms/step - loss: 0.9503 - accuracy: 0.6060\n",
            "Accuracy score is  0.6060000061988831 Loss is  0.9502753615379333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM_aUryY-V8N",
        "outputId": "4f52dc66-02fe-4a59-ce38-c42596deb918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "307/307 [==============================] - 213s 683ms/step - loss: 0.6442 - accuracy: 0.6172 - val_loss: 0.5839 - val_accuracy: 0.6980\n",
            "Epoch 2/10\n",
            "307/307 [==============================] - 228s 743ms/step - loss: 0.5765 - accuracy: 0.7045 - val_loss: 0.5648 - val_accuracy: 0.7176\n",
            "Epoch 3/10\n",
            "307/307 [==============================] - 232s 758ms/step - loss: 0.5591 - accuracy: 0.7148 - val_loss: 0.5773 - val_accuracy: 0.6882\n",
            "Epoch 4/10\n",
            "307/307 [==============================] - 235s 766ms/step - loss: 0.5297 - accuracy: 0.7342 - val_loss: 0.5450 - val_accuracy: 0.7296\n",
            "Epoch 5/10\n",
            "307/307 [==============================] - 216s 703ms/step - loss: 0.5116 - accuracy: 0.7467 - val_loss: 0.5551 - val_accuracy: 0.7153\n",
            "Epoch 6/10\n",
            "307/307 [==============================] - 216s 703ms/step - loss: 0.4931 - accuracy: 0.7583 - val_loss: 0.5582 - val_accuracy: 0.7206\n",
            "Epoch 7/10\n",
            "307/307 [==============================] - 222s 723ms/step - loss: 0.4688 - accuracy: 0.7755 - val_loss: 0.5609 - val_accuracy: 0.7343\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d475c27dcf0>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "model_extreme.fit(X_train_extreme, y_train_extreme, epochs=10, validation_split=0.2, verbose=1, batch_size=64, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the performance of the original NN model\n",
        "loss, accuracy = model_extreme.evaluate(X_test_extreme, y_test_extreme)\n",
        "print(\"Accuracy score is \", accuracy, \"Loss is \", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCrShd7PTMpK",
        "outputId": "137c7acb-e7b3-46d1-8219-860510710a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329/329 [==============================] - 36s 111ms/step - loss: 0.5547 - accuracy: 0.7210\n",
            "Accuracy score is  0.7209523916244507 Loss is  0.5546982884407043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We also tested the accuracy of a Naive Bayes model\n",
        "# seems that with the NB model has better performance in predicting extreme scores than our NN model\n",
        "X_nb, y_nb = rev_lemmatized_extreme['lemmatized_text'].apply(lambda x:\" \".join(x)) ,rev_lemmatized_extreme['extreme_rate']\n",
        "X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X_nb, y_nb, test_size=0.2, random_state=42)\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_nb_vector_data = vectorizer.fit_transform(X_train_nb)\n",
        "X_test_nb_vector_data = vectorizer.transform(X_test_nb)"
      ],
      "metadata": {
        "id": "8tnJQDNsTRhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_extreme_nb = MultinomialNB()\n",
        "model_extreme_nb.fit(X_train_nb_vector_data,y_train_nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "jYiNSEXgXMy4",
        "outputId": "fe3ba168-5019-4628-fd00-7add47ae47ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_nb = model_extreme_nb.predict(X_test_nb_vector_data)\n",
        "accuracy = accuracy_score(y_test_nb, y_pred_nb)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj38Xy1pThog",
        "outputId": "054a741c-57c6-45eb-ebdc-76e9ff6185fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7364285714285714"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQj6z-MniULM"
      },
      "outputs": [],
      "source": [
        "model_15.fit(X_train_15, y_train_15, epochs=10, validation_split=0.2, verbose=1, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1RelAfoiZLw"
      },
      "outputs": [],
      "source": [
        "model_234.fit(X_train_234, y_train_234, epochs=10, validation_split=0.2, verbose=1, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csSNOLBliwSf"
      },
      "outputs": [],
      "source": [
        "# The following code is combining three Neural Network models to predict new dataset\n",
        "# Although we have seperate ratings and model_15, model_234 showed significant improvement over the accuracy\n",
        "# Combined together with the first neural network to predict extreme score will lower the overall accuracy\n",
        "# due to the fact that error will multiply with each other\n",
        "\n",
        "df_validate = rev # can be replaced with any other new review data as long as you import it as a dataframe and it contains ['text'] column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmfioHYSiwZ-"
      },
      "outputs": [],
      "source": [
        "df_validate[\"lemmatized_text\"] = df_validate[\"text\"].apply(clean_and_tokenize)\n",
        "df_validate = df_validate[[\"lemmatized_text\",'stars']]\n",
        "df_validate.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_val = Tokenizer(num_words=review_cnt_limit)\n",
        "tokenizer_val.fit_on_texts(df_validate[\"lemmatized_text\"])\n",
        "sequence_val = tokenizer_val.texts_to_sequences(df_validate[\"lemmatized_text\"])\n",
        "validate_extreme = pad_sequences(sequence_val, maxlen=maxlen)\n",
        "prediction_val = model_extreme.predict(validate_extreme)"
      ],
      "metadata": {
        "id": "QQzvosd85LIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "binary_predictions = [1 if prob[1] > threshold else 0 for prob in prediction_val]"
      ],
      "metadata": {
        "id": "KyP4D__d5MZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_validate['Predicted_Extreme_Score'] = binary_predictions\n",
        "df_validate.head()"
      ],
      "metadata": {
        "id": "iOidu1Sf5OBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_15 = df_validate[df_validate['Predicted_Extreme_Score'] == 1]\n",
        "df_15.shape"
      ],
      "metadata": {
        "id": "WsjDLIee5PTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_val_15 = Tokenizer(num_words=review_cnt_limit)\n",
        "tokenizer_val_15.fit_on_texts(df_15[\"lemmatized_text\"])\n",
        "sequence_val_15 = tokenizer_val_15.texts_to_sequences(df_15[\"lemmatized_text\"])\n",
        "validate_15 = pad_sequences(sequence_val_15, maxlen=maxlen)\n",
        "prediction_15 = model_15.predict(validate_15)"
      ],
      "metadata": {
        "id": "4Zd_kC6f5QWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_five_predictions = [5 if prob[1] > threshold else 1 for prob in prediction_15]\n",
        "df_15['Predicted_Score'] = one_five_predictions\n",
        "df_15.head(20)"
      ],
      "metadata": {
        "id": "ZFgaArxo5SMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_234 = df_validate[df_validate['Predicted_Extreme_Score'] == 0]\n",
        "df_234.shape"
      ],
      "metadata": {
        "id": "9TItjxVc5TQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_val_234 = Tokenizer(num_words=review_cnt_limit)\n",
        "tokenizer_val_234.fit_on_texts(df_234[\"lemmatized_text\"])\n",
        "sequence_val_234 = tokenizer_val_234.texts_to_sequences(df_234[\"lemmatized_text\"])\n",
        "validate_234 = pad_sequences(sequence_val_234, maxlen=maxlen)\n",
        "prediction_234 = model_234.predict(validate_234)"
      ],
      "metadata": {
        "id": "9UICgGcv5UQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_234 = np.argmax(prediction_234, axis=1)"
      ],
      "metadata": {
        "id": "lhJLQkHF5VuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_234['Predicted_Score'] = prediction_234\n",
        "df_234['Predicted_Score'] = df_234['Predicted_Score'].replace(2,4)\n",
        "df_234['Predicted_Score'] = df_234['Predicted_Score'].replace(1,3)\n",
        "df_234['Predicted_Score'] = df_234['Predicted_Score'].replace(0,2)\n",
        "df_234.head(20)"
      ],
      "metadata": {
        "id": "Mnmaz_Q25W8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = pd.concat([df_15, df_234], ignore_index=True)\n",
        "df_result.head(20)"
      ],
      "metadata": {
        "id": "ritx-6q85YCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = (df_result['Predicted_Score'] == df_result['stars']).sum()\n",
        "total_predictions = len(df_result)\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "qDFKKoAL5ZAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsVaTgg7-YHq"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model_extreme.evaluate(X_test, y_test)\n",
        "print(\"Accuracy score is \", accuracy, \"Loss is \", loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}